{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, \\\n",
    "ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.predictor import RealTimePredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparamaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "num_training_samples = 5216\n",
    "num_layers = 18\n",
    "mini_batch_size = 128\n",
    "image_shape = '3,224,224'\n",
    "augmentation_type = 'crop_color_transform'\n",
    "epochs = 3\n",
    "learning_rate = 0.01\n",
    "use_pretrained_model = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name_prefix = 'pneumonia-detection'\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "job_name = job_name_prefix + timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "input_prefix = 'chest_xray_recordio'\n",
    "input_train = 's3://{}/{}/train/'.format(bucket, input_prefix)\n",
    "input_test = 's3://{}/{}/test/'.format(bucket, input_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_prefix = 'chest_xray_output'\n",
    "output_path = 's3://{}/{}/'.format(bucket, output_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_count = 1\n",
    "instance_type = 'ml.p2.xlarge'\n",
    "volume_size_gb = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timeout = 360000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get role and training image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "training_image = get_image_uri(boto3.Session().region_name, \n",
    "                               'image-classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimator = sagemaker.estimator.Estimator(training_image, \n",
    "                                          role, \n",
    "                                          train_instance_count=instance_count,\n",
    "                                          train_instance_type=instance_type,\n",
    "                                          train_volume_size=volume_size_gb,\n",
    "                                          train_max_run=train_timeout,\n",
    "                                          output_path=output_path, \n",
    "                                          sagemaker_session=sagemaker_session,\n",
    "                                         input_mode='Pipe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(num_classes=num_classes,\n",
    "                              num_training_samples=num_training_samples,\n",
    "                              num_layers=num_layers,\n",
    "                              mini_batch_size=mini_batch_size,\n",
    "                              image_shape=image_shape,\n",
    "                              augmentation_type=augmentation_type,\n",
    "                              epochs=epochs,\n",
    "                              learning_rate=learning_rate,\n",
    "                              use_pretrained_model=use_pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.s3_input(s3_data=input_train,\n",
    "                                    content_type='application/x-recordio')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data=input_test,\n",
    "                                        content_type='application/x-recordio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-06 23:07:11 Starting - Starting the training job...\n",
      "2020-04-06 23:07:12 Starting - Launching requested ML instances...\n",
      "2020-04-06 23:08:08 Starting - Preparing the instances for training.........\n",
      "2020-04-06 23:09:40 Downloading - Downloading input data...\n",
      "2020-04-06 23:10:00 Training - Downloading the training image......\n",
      "2020-04-06 23:11:03 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/image_classification/default-input.json: {u'beta_1': 0.9, u'gamma': 0.9, u'beta_2': 0.999, u'optimizer': u'sgd', u'use_pretrained_model': 0, u'eps': 1e-08, u'epochs': 30, u'lr_scheduler_factor': 0.1, u'num_layers': 152, u'image_shape': u'3,224,224', u'precision_dtype': u'float32', u'mini_batch_size': 32, u'weight_decay': 0.0001, u'learning_rate': 0.1, u'momentum': 0}\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'0.01', u'use_pretrained_model': u'1', u'epochs': u'3', u'augmentation_type': u'crop_color_transform', u'num_layers': u'18', u'mini_batch_size': u'128', u'image_shape': u'3,224,224', u'num_classes': u'2', u'num_training_samples': u'5216'}\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] Final configuration: {u'optimizer': u'sgd', u'learning_rate': u'0.01', u'epochs': u'3', u'lr_scheduler_factor': 0.1, u'num_layers': u'18', u'num_classes': u'2', u'precision_dtype': u'float32', u'mini_batch_size': u'128', u'augmentation_type': u'crop_color_transform', u'beta_1': 0.9, u'beta_2': 0.999, u'use_pretrained_model': u'1', u'eps': 1e-08, u'weight_decay': 0.0001, u'momentum': 0, u'image_shape': u'3,224,224', u'gamma': 0.9, u'num_training_samples': u'5216'}\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] use_pretrained_model: 1\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] multi_label: 0\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] Using pretrained model for initializing weights and transfer learning.\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] ---- Parameters ----\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] num_layers: 18\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] data type: <type 'numpy.float32'>\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] epochs: 3\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] optimizer: sgd\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] momentum: 0.9\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] weight_decay: 0.0001\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] learning_rate: 0.01\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] num_training_samples: 5216\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] mini_batch_size: 128\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] image_shape: 3,224,224\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] num_classes: 2\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] augmentation_type: crop_color_transform\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] kv_store: device\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] checkpoint_frequency not set, will store the best model\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] --------------------\u001b[0m\n",
      "\u001b[34m[23:11:06] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_ecl_Cuda_10.1.x.2633.0/AL2012/generic-flavor/src/src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\u001b[0m\n",
      "\u001b[34m[23:11:06] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_ecl_Cuda_10.1.x.2633.0/AL2012/generic-flavor/src/src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:06 INFO 140030151333696] Setting number of threads: 3\u001b[0m\n",
      "\u001b[34m[23:11:11] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_ecl_Cuda_10.1.x.2633.0/AL2012/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:33 INFO 140030151333696] Epoch[0] Batch [20]#011Speed: 115.749 samples/sec#011accuracy=0.893229\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:48 INFO 140030151333696] Epoch[0] Train-accuracy=0.923633\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:48 INFO 140030151333696] Epoch[0] Time cost=37.364\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:50 INFO 140030151333696] Epoch[0] Validation-accuracy=0.857812\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:50 INFO 140030151333696] Storing the best model with validation accuracy: 0.857812\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:11:50 INFO 140030151333696] Saved checkpoint to \"/opt/ml/model/image-classification-0001.params\"\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:12:07 INFO 140030151333696] Epoch[1] Batch [20]#011Speed: 155.410 samples/sec#011accuracy=0.973958\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:12:22 INFO 140030151333696] Epoch[1] Train-accuracy=0.973633\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:12:22 INFO 140030151333696] Epoch[1] Time cost=31.751\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:12:24 INFO 140030151333696] Epoch[1] Validation-accuracy=0.878125\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:12:24 INFO 140030151333696] Storing the best model with validation accuracy: 0.878125\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:12:24 INFO 140030151333696] Saved checkpoint to \"/opt/ml/model/image-classification-0002.params\"\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:12:41 INFO 140030151333696] Epoch[2] Batch [20]#011Speed: 155.131 samples/sec#011accuracy=0.980655\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:12:56 INFO 140030151333696] Epoch[2] Train-accuracy=0.979492\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:12:56 INFO 140030151333696] Epoch[2] Time cost=31.799\u001b[0m\n",
      "\u001b[34m[04/06/2020 23:12:58 INFO 140030151333696] Epoch[2] Validation-accuracy=0.812500\u001b[0m\n",
      "\n",
      "2020-04-06 23:13:11 Uploading - Uploading generated training model\n",
      "2020-04-06 23:13:11 Completed - Training job completed\n",
      "Training seconds: 211\n",
      "Billable seconds: 211\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({\n",
    "    'train': s3_input_train,\n",
    "    'validation': s3_input_validation\n",
    "}, job_name=job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    'learning_rate': ContinuousParameter(0.001, 1.0),\n",
    "    'mini_batch_size': IntegerParameter(64, 128),\n",
    "    'optimizer': CategoricalParameter(['sgd', 'adam'])\n",
    "}\n",
    "\n",
    "objective_metric_name = 'validation:accuracy'\n",
    "objective_type='Maximize'\n",
    "max_jobs=6\n",
    "max_parallel_jobs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name_prefix = 'bcd-tuning'\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "job_name = job_name_prefix + timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(estimator=estimator,\n",
    "                            objective_metric_name=objective_metric_name, \n",
    "                            hyperparameter_ranges=hyperparameter_ranges,\n",
    "                            objective_type=objective_type, \n",
    "                            max_jobs=max_jobs, \n",
    "                            max_parallel_jobs=max_parallel_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................................!\n"
     ]
    }
   ],
   "source": [
    "tuner.fit({\n",
    "    'train': s3_input_train,\n",
    "    'validation': s3_input_validation\n",
    "}, job_name=job_name)\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "hosting_image = get_image_uri(boto3.Session().region_name, 'image-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "instance_count = 1\n",
    "instance_type = 'ml.m4.xlarge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_prefix = 'pnu-image-classification-tuned'\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "model_name = model_name_prefix + timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifacts_s3_path = 's3://sagemaker-us-east-2-755441266669/chest_xray_output/bcd-tuning-2020-04-06-23-13-43-002-f524bc13/output/model.tar.gz'\n",
    "model = Model(\n",
    "    name=model_name,\n",
    "    model_data=model_artifacts_s3_path,\n",
    "    image=hosting_image,\n",
    "    role=role,\n",
    "    predictor_cls=lambda endpoint_name, sagemaker_session: RealTimePredictor(endpoint_name, sagemaker_session)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name_prefix = 'pneumonia-detection-ep'\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "endpoint_name = endpoint_name_prefix + timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_count = 1\n",
    "instance_type = 'ml.m4.xlarge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = model.deploy(\n",
    "    endpoint_name=endpoint_name,\n",
    "    initial_instance_count=instance_count,\n",
    "    instance_type=instance_type\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "def predict_pneumonia(image_path):\n",
    "    with open(image_path, 'rb') as f:\n",
    "        payload = f.read()\n",
    "        payload = bytearray(payload)\n",
    "    response = predictor.predict(payload)\n",
    "    result = json.loads(response)\n",
    "    print('Probabilities for all classes: ', result)\n",
    "    predicted_class = np.argmax(result)\n",
    "    if predicted_class == 0:\n",
    "        print('Pneumonia not detected')\n",
    "        return 0\n",
    "    else:\n",
    "        print('Pneumonia detected')\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = glob.glob(\"/home/ec2-user/SageMaker/{0}/val/{1}/*.jpeg\".format(\n",
    "                                                    'chest_xray_standard', \n",
    "                                                    'PNEUMONIA'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for all classes:  [0.027903562411665916, 0.9720964431762695]\n",
      "Pneumonia detected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_pneumonia(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = glob.glob(\"/home/ec2-user/SageMaker/{0}/val/{1}/*.jpeg\".format(\n",
    "                                                    'chest_xray_standard', \n",
    "                                                    'NORMAL'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for all classes:  [0.9990615248680115, 0.0009384835138916969]\n",
      "Pneumonia not detected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_pneumonia(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metrics(confusion_matrix):\n",
    "    tn, fn, fp, tp = confusion_matrix[0][0], confusion_matrix[0][1], confusion_matrix[1][0], confusion_matrix[1][1]\n",
    "    accuracy = sum([tn, tp])/sum([tn, fn, fp, tp])\n",
    "    precision = sum([tp])/ sum([tp, fp])\n",
    "    recall = sum([tp])/ sum([tp, fn])\n",
    "    f1_score = 2 * ((precision * recall)/(precision + recall))\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1_score}\")\n",
    "    return accuracy, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = glob.glob(\"/home/ec2-user/SageMaker/{0}/val/*/*.jpeg\".format('chest_xray_standard'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for all classes:  [0.9990615248680115, 0.0009384835138916969]\n",
      "Pneumonia not detected\n",
      "Probabilities for all classes:  [0.9997650980949402, 0.000234856634051539]\n",
      "Pneumonia not detected\n",
      "Probabilities for all classes:  [0.9978341460227966, 0.0021658455953001976]\n",
      "Pneumonia not detected\n",
      "Probabilities for all classes:  [0.9846579432487488, 0.01534203439950943]\n",
      "Pneumonia not detected\n",
      "Probabilities for all classes:  [0.9722853899002075, 0.02771466225385666]\n",
      "Pneumonia not detected\n",
      "Probabilities for all classes:  [0.9712350964546204, 0.028764856979250908]\n",
      "Pneumonia not detected\n",
      "Probabilities for all classes:  [0.9901774525642395, 0.009822608903050423]\n",
      "Pneumonia not detected\n",
      "Probabilities for all classes:  [0.9956036806106567, 0.004396365024149418]\n",
      "Pneumonia not detected\n",
      "Probabilities for all classes:  [0.027903562411665916, 0.9720964431762695]\n",
      "Pneumonia detected\n",
      "Probabilities for all classes:  [4.5117038098396733e-05, 0.9999549388885498]\n",
      "Pneumonia detected\n",
      "Probabilities for all classes:  [8.050664291658904e-06, 0.9999918937683105]\n",
      "Pneumonia detected\n",
      "Probabilities for all classes:  [0.002314954297617078, 0.9976850748062134]\n",
      "Pneumonia detected\n",
      "Probabilities for all classes:  [0.004225576296448708, 0.9957744479179382]\n",
      "Pneumonia detected\n",
      "Probabilities for all classes:  [0.010303889401257038, 0.9896961450576782]\n",
      "Pneumonia detected\n",
      "Probabilities for all classes:  [0.003535483032464981, 0.9964644908905029]\n",
      "Pneumonia detected\n",
      "Probabilities for all classes:  [0.00024787697475403547, 0.9997521042823792]\n",
      "Pneumonia detected\n"
     ]
    }
   ],
   "source": [
    "predictions = list([ predict_pneumonia(data) for data in dataset ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_labels = [ (1 if ('PNEUMONIA' in data) else 0) for data in dataset ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prediction  0  1\n",
       "actual          \n",
       "0           8  0\n",
       "1           0  8"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(index=np.array(all_image_labels), columns=np.array(predictions),\n",
    "                               rownames=['actual'], colnames=['prediction'])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
